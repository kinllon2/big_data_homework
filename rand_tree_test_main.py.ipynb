{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd2a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random_forest.random_forest_model import RandomForest\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import nltk\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd49590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local path of the data source\n",
    "testing_data = 'data/testing.csv'\n",
    "training_data = 'data/training.csv'\n",
    "validation_data = 'data/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dc7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_clean(review): \n",
    "    # changing to lower case\n",
    "    lower = review.str.lower()\n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n",
    "    # Removing all the special Characters\n",
    "    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    # Removing all the non ASCII characters\n",
    "    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n",
    "    # Replacing Two or more dots with one\n",
    "    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb44850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(review):\n",
    "    # Sentiment polarity of the reviews\n",
    "    pol = []\n",
    "    for i in review:\n",
    "        analysis = TextBlob(i)\n",
    "        pol.append(analysis.sentiment.polarity)\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cc24c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4155\n",
       "1.0    4004\n",
       "Name: Review_Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three data given by the COMP5434 project\n",
    "train = pd.read_csv(training_data)\n",
    "validation = pd.read_csv(validation_data)\n",
    "test = pd.read_csv(testing_data)\n",
    "\n",
    "data = pd.concat([train, validation])\n",
    "data['review_clean'] = review_clean(data['reviewComment'])\n",
    "# Removing the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['review_clean'] = data['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "# Removing the word stems using the Snowball Stemmer\n",
    "Snow_ball = SnowballStemmer(\"english\")\n",
    "data['review_clean'] = data['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))\n",
    "\n",
    "data['sentiment'] = sentiment(data['reviewComment'])\n",
    "data['sentiment_clean'] = sentiment(data['review_clean'])\n",
    "# Cleaning the reviews without removing the stop words and using snowball stemmer\n",
    "data['review_clean_ss'] = review_clean(data['reviewComment'])\n",
    "data['sentiment_clean_ss'] = sentiment(data['review_clean_ss'])\n",
    "data = data.dropna(how=\"any\", axis=0)\n",
    "#Word count in each review\n",
    "data['count_word']=data[\"review_clean_ss\"].apply(lambda x: len(str(x).split()))\n",
    "#Unique word count \n",
    "data['count_unique_word']=data[\"review_clean_ss\"].apply(lambda x: len(set(str(x).split())))\n",
    "#Letter count\n",
    "data['count_letters']=data[\"review_clean_ss\"].apply(lambda x: len(str(x)))\n",
    "#punctuation count\n",
    "data[\"count_punctuations\"] = data[\"reviewComment\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "#upper case words count\n",
    "data[\"count_words_upper\"] = data[\"reviewComment\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "#title case words count\n",
    "data[\"count_words_title\"] = data[\"reviewComment\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "#Number of stopwords\n",
    "data[\"count_stopwords\"] = data[\"reviewComment\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "#Average length of the words\n",
    "data[\"mean_word_len\"] = data[\"review_clean_ss\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "# Label Encoding Drugname and Conditions\n",
    "label_encoder_feat = {}\n",
    "for feature in ['drugName', 'condition']:\n",
    "    label_encoder_feat[feature] = LabelEncoder()\n",
    "    data[feature] = label_encoder_feat[feature].fit_transform(data[feature])\n",
    "\n",
    "# converting the date into datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors = 'coerce')\n",
    "\n",
    "# now extracting year from date\n",
    "data['Year'] = data['date'].dt.year\n",
    "\n",
    "# extracting the month from the date\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# extracting the days from the date\n",
    "data['day'] = data['date'].dt.day\n",
    "\n",
    "data.loc[(data['rating'] >= 5), 'Review_Sentiment'] = 1\n",
    "data.loc[(data['rating'] < 5), 'Review_Sentiment'] = 0\n",
    "\n",
    "data['Review_Sentiment'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e38913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>reviewComment</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>Year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Review_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163740</td>\n",
       "      <td>833</td>\n",
       "      <td>123</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>22</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>5</td>\n",
       "      <td>ive tri antidepress year citalopram fluoxetin ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>410</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>5.134328</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206473</td>\n",
       "      <td>785</td>\n",
       "      <td>116</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>17</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>4</td>\n",
       "      <td>son crohn diseas done well asacol complaint sh...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>246</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.145833</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159672</td>\n",
       "      <td>153</td>\n",
       "      <td>402</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>3</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>5</td>\n",
       "      <td>quick reduct symptom</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39293</td>\n",
       "      <td>300</td>\n",
       "      <td>417</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>35</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>5</td>\n",
       "      <td>contrav combin drug use alcohol smoke opioid c...</td>\n",
       "      <td>0.139063</td>\n",
       "      <td>...</td>\n",
       "      <td>724</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97768</td>\n",
       "      <td>315</td>\n",
       "      <td>73</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>4</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>5</td>\n",
       "      <td>birth control one cycl read review type simila...</td>\n",
       "      <td>0.260926</td>\n",
       "      <td>...</td>\n",
       "      <td>739</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>3.966443</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordId  drugName  condition  \\\n",
       "0    163740       833        123   \n",
       "1    206473       785        116   \n",
       "2    159672       153        402   \n",
       "3     39293       300        417   \n",
       "4     97768       315         73   \n",
       "\n",
       "                                       reviewComment       date  usefulCount  \\\n",
       "0  \"I&#039;ve tried a few antidepressants over th... 2012-02-28           22   \n",
       "1  \"My son has Crohn&#039;s disease and has done ... 2009-05-17           17   \n",
       "2                      \"Quick reduction of symptoms\" 2017-09-29            3   \n",
       "3  \"Contrave combines drugs that were used for al... 2017-03-05           35   \n",
       "4  \"I have been on this birth control for one cyc... 2015-10-22            4   \n",
       "\n",
       "           sideEffects  rating  \\\n",
       "0    Mild Side Effects       5   \n",
       "1  Severe Side Effects       4   \n",
       "2      No Side Effects       5   \n",
       "3    Mild Side Effects       5   \n",
       "4  Severe Side Effects       5   \n",
       "\n",
       "                                        review_clean  sentiment  ...  \\\n",
       "0  ive tri antidepress year citalopram fluoxetin ...   0.000000  ...   \n",
       "1  son crohn diseas done well asacol complaint sh...   0.566667  ...   \n",
       "2                               quick reduct symptom   0.333333  ...   \n",
       "3  contrav combin drug use alcohol smoke opioid c...   0.139063  ...   \n",
       "4  birth control one cycl read review type simila...   0.260926  ...   \n",
       "\n",
       "   count_letters count_punctuations  count_words_upper  count_words_title  \\\n",
       "0            410                 22                  2                  4   \n",
       "1            246                 13                  0                  4   \n",
       "2             27                  2                  0                  1   \n",
       "3            724                 42                 10                 14   \n",
       "4            739                 17                 10                 17   \n",
       "\n",
       "   count_stopwords  mean_word_len  Year  month  day  Review_Sentiment  \n",
       "0               27       5.134328  2012      2   28               1.0  \n",
       "1               22       4.145833  2009      5   17               0.0  \n",
       "2                1       6.000000  2017      9   29               1.0  \n",
       "3               71       4.000000  2017      3    5               1.0  \n",
       "4               80       3.966443  2015     10   22               1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf970712",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['condition', 'usefulCount', 'sentiment', 'day', 'month', 'Year',\n",
    "                'sentiment_clean_ss', 'count_word', 'count_unique_word', 'count_letters',\n",
    "                'count_punctuations', 'count_words_upper', 'count_words_title',\n",
    "                'count_stopwords', 'mean_word_len']]\n",
    "\n",
    "target = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60661f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6527, 15)\n",
      "Y_train.shape: (6527,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 20)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"Y_train.shape:\", y_train.shape)\n",
    "\n",
    "# clf = RandomForest(n_estimators=100)\n",
    "# clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3651f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rf0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eca6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf0.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb84f4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, ..., 5, 5, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e01143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5263480392156863\n"
     ]
    }
   ],
   "source": [
    "from utils import train_test_split, accuracy_score, Plot\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3cd1a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60d964d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d1b3de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "      <th>sentiment_clean_ss</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>359</td>\n",
       "      <td>54</td>\n",
       "      <td>0.213420</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.213420</td>\n",
       "      <td>132</td>\n",
       "      <td>97</td>\n",
       "      <td>713</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>4.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>371</td>\n",
       "      <td>60</td>\n",
       "      <td>0.076894</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>132</td>\n",
       "      <td>94</td>\n",
       "      <td>746</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>4.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>153</td>\n",
       "      <td>99</td>\n",
       "      <td>718</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>3.699346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>163</td>\n",
       "      <td>38</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>143</td>\n",
       "      <td>106</td>\n",
       "      <td>712</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>3.986014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>355</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>212</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>408</td>\n",
       "      <td>9</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>278</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>564</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>4.539216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>415</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6527 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      condition  usefulCount  sentiment  day  month  Year  sentiment_clean_ss  \\\n",
       "527          81            9  -0.060000   21      1  2016           -0.060000   \n",
       "1270        359           54   0.213420   17      8  2014            0.213420   \n",
       "6442        371           60   0.076894   21      7  2014            0.028819   \n",
       "72           23           13   0.292000   11      8  2015            0.292000   \n",
       "866         163           38   0.051369   26      3  2016            0.053452   \n",
       "...         ...          ...        ...  ...    ...   ...                 ...   \n",
       "103         355            5   0.458333    3      9  2011            0.458333   \n",
       "428         408            9   0.033333    7      6  2017            0.033333   \n",
       "4390        279            1   0.248571    5      3  2008            0.248571   \n",
       "2537        364           12   0.045000   23      3  2016            0.005000   \n",
       "560         415            2   0.800000    6     10  2015            0.800000   \n",
       "\n",
       "      count_word  count_unique_word  count_letters  count_punctuations  \\\n",
       "527           58                 44            293                   9   \n",
       "1270         132                 97            713                  20   \n",
       "6442         132                 94            746                  29   \n",
       "72           153                 99            718                  23   \n",
       "866          143                106            712                  41   \n",
       "...          ...                ...            ...                 ...   \n",
       "103           45                 35            212                   8   \n",
       "428           54                 45            278                  13   \n",
       "4390          34                 30            180                   5   \n",
       "2537         102                 74            564                  15   \n",
       "560           14                 14             61                   4   \n",
       "\n",
       "      count_words_upper  count_words_title  count_stopwords  mean_word_len  \n",
       "527                   6                  9               23       4.068966  \n",
       "1270                  4                  9               55       4.409091  \n",
       "6442                  4                 10               57       4.659091  \n",
       "72                   17                 21               73       3.699346  \n",
       "866                   6                 12               64       3.986014  \n",
       "...                 ...                ...              ...            ...  \n",
       "103                   3                  5               25       3.733333  \n",
       "428                   3                  4               27       4.166667  \n",
       "4390                  2                  2               17       4.323529  \n",
       "2537                  4                 13               44       4.539216  \n",
       "560                   2                  4                4       3.428571  \n",
       "\n",
       "[6527 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainY = create_dataset(train, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a44acee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "508840a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d79bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5263480392156863\n"
     ]
    }
   ],
   "source": [
    "from utils import train_test_split, accuracy_score, Plot\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3352d",
   "metadata": {},
   "source": [
    "### test data predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189f6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three data given by the COMP5434 project\n",
    "\n",
    "test = pd.read_csv(testing_data)\n",
    "test['review_clean'] = review_clean(test['reviewComment'])\n",
    "# Removing the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test['review_clean'] = test['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "# Removing the word stems using the Snowball Stemmer\n",
    "Snow_ball = SnowballStemmer(\"english\")\n",
    "test['review_clean'] = test['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))\n",
    "\n",
    "test['sentiment'] = sentiment(test['reviewComment'])\n",
    "test['sentiment_clean'] = sentiment(test['review_clean'])\n",
    "# Cleaning the reviews without removing the stop words and using snowball stemmer\n",
    "test['review_clean_ss'] = review_clean(test['reviewComment'])\n",
    "test['sentiment_clean_ss'] = sentiment(test['review_clean_ss'])\n",
    "\n",
    "#Word count in each review\n",
    "test['count_word']=test[\"review_clean_ss\"].apply(lambda x: len(str(x).split()))\n",
    "#Unique word count \n",
    "test['count_unique_word']=test[\"review_clean_ss\"].apply(lambda x: len(set(str(x).split())))\n",
    "#Letter count\n",
    "test['count_letters']=test[\"review_clean_ss\"].apply(lambda x: len(str(x)))\n",
    "#punctuation count\n",
    "test[\"count_punctuations\"] = test[\"reviewComment\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "#upper case words count\n",
    "test[\"count_words_upper\"] = test[\"reviewComment\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "#title case words count\n",
    "test[\"count_words_title\"] = test[\"reviewComment\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "#Number of stopwords\n",
    "test[\"count_stopwords\"] = test[\"reviewComment\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "#Average length of the words\n",
    "test[\"mean_word_len\"] = test[\"review_clean_ss\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "# Label Encoding Drugname and Conditions\n",
    "label_encoder_feat = {}\n",
    "for feature in ['drugName', 'condition']:\n",
    "    label_encoder_feat[feature] = LabelEncoder()\n",
    "    test[feature] = label_encoder_feat[feature].fit_transform(test[feature])\n",
    "\n",
    "# converting the date into datetime format\n",
    "test['date'] = pd.to_datetime(test['date'], errors = 'coerce')\n",
    "\n",
    "# now extracting year from date\n",
    "test['Year'] = test['date'].dt.year\n",
    "\n",
    "# extracting the month from the date\n",
    "test['month'] = test['date'].dt.month\n",
    "\n",
    "# extracting the days from the date\n",
    "test['day'] = test['date'].dt.day\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c521556",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXXX = test[['condition', 'usefulCount', 'sentiment', 'day', 'month', 'Year',\n",
    "                'sentiment_clean_ss', 'count_word', 'count_unique_word', 'count_letters',\n",
    "                'count_punctuations', 'count_words_upper', 'count_words_title',\n",
    "                'count_stopwords', 'mean_word_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25ebbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be934e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "      <th>sentiment_clean_ss</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>105</td>\n",
       "      <td>73</td>\n",
       "      <td>539</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.102381</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>-0.102381</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "      <td>439</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>4.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>359</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.137753</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>-0.137753</td>\n",
       "      <td>112</td>\n",
       "      <td>79</td>\n",
       "      <td>574</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>4.133929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>143</td>\n",
       "      <td>86</td>\n",
       "      <td>708</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>3.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>128</td>\n",
       "      <td>176</td>\n",
       "      <td>0.151937</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.104650</td>\n",
       "      <td>141</td>\n",
       "      <td>89</td>\n",
       "      <td>682</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>68</td>\n",
       "      <td>3.843972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>234</td>\n",
       "      <td>8</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>293</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>4.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.240774</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.216369</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>3.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>177</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.049167</td>\n",
       "      <td>132</td>\n",
       "      <td>88</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>4.469697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>91</td>\n",
       "      <td>17</td>\n",
       "      <td>0.264694</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.264694</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>581</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>4.150442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1798 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      condition  usefulCount  sentiment  day  month  Year  sentiment_clean_ss  \\\n",
       "0            42            1   0.012500   10      9  2017            0.012500   \n",
       "1            64            0  -0.102381   29      8  2017           -0.102381   \n",
       "2            90           13   0.020455    6      7  2015            0.020455   \n",
       "3           221            7  -0.137753    7      7  2011           -0.137753   \n",
       "4           150           11  -0.017045    1     10  2009           -0.017045   \n",
       "...         ...          ...        ...  ...    ...   ...                 ...   \n",
       "1793        128          176   0.151937    9      8  2014            0.104650   \n",
       "1794        234            8   0.021693   26      3  2016            0.021693   \n",
       "1795         90            2   0.240774   12      8  2015            0.216369   \n",
       "1796        177           58  -0.066667    2      2  2010           -0.049167   \n",
       "1797         91           17   0.264694   26      8  2015            0.264694   \n",
       "\n",
       "      count_word  count_unique_word  count_letters  count_punctuations  \\\n",
       "0            105                 73            539                  23   \n",
       "1             78                 68            439                  16   \n",
       "2             70                 54            359                  31   \n",
       "3            112                 79            574                  19   \n",
       "4            143                 86            708                  32   \n",
       "...          ...                ...            ...                 ...   \n",
       "1793         141                 89            682                  35   \n",
       "1794          58                 44            293                  13   \n",
       "1795          72                 53            330                  14   \n",
       "1796         132                 88            721                  23   \n",
       "1797         113                 87            581                  21   \n",
       "\n",
       "      count_words_upper  count_words_title  count_stopwords  mean_word_len  \n",
       "0                     8                 15               45       4.142857  \n",
       "1                     2                  7               31       4.641026  \n",
       "2                     5                  7               23       4.142857  \n",
       "3                     7                 13               54       4.133929  \n",
       "4                    16                 25               69       3.958042  \n",
       "...                 ...                ...              ...            ...  \n",
       "1793                  9                 13               68       3.843972  \n",
       "1794                  6                  8               23       4.068966  \n",
       "1795                  9                 11               36       3.597222  \n",
       "1796                  6                 19               59       4.469697  \n",
       "1797                  4                 12               49       4.150442  \n",
       "\n",
       "[1798 rows x 15 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "252ba895",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_array = rf0.predict(testXXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3716312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1798"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1357e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "test = pd.read_csv(testing_data)\n",
    "test['rating'] = temp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "890dd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/testing2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
